{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage.measure import compare_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# в обох варіантах використаємо підхід, що полягає в видаленні кожного 2 кадру. також всі важливі кадри будемо зберігати в папках decoded, original та differ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('slow.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode1(cap):\n",
    "    encoded = []\n",
    "    ret, previmg = cap.read()\n",
    "    i = 1\n",
    "    while (True):\n",
    "        ret, img = cap.read()\n",
    "        if (ret == 0): break\n",
    "        if (i % 2 == 0 ):\n",
    "            previmg = img\n",
    "        else:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            prevgray = cv2.cvtColor(previmg, cv2.COLOR_BGR2GRAY)\n",
    "            flow = cv2.calcOpticalFlowFarneback(prevgray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            code = np.concatenate((previmg, flow), axis = -1)\n",
    "            encoded.append(code)\n",
    "        i += 1\n",
    "        '''\n",
    "        if (i == 8): \n",
    "            encoded = np.array(encoded)\n",
    "            \n",
    "            return encoded\n",
    "        '''\n",
    "        ch = 0xFF & cv2.waitKey(5)\n",
    "        if ch == 27:\n",
    "            break\n",
    "    return np.array(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded1 = encode1(cap)\n",
    "with open('encoded1.npy', 'wb') as f:\n",
    "    np.save(f, encoded1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# зсуваємо кожен піксель на flow порахований методом farneback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_flow(img, flow):\n",
    "    tmp = img\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            for k in range(img.shape[2]):\n",
    "                try:\n",
    "                    tmp[int(i+flow[i,j,0]),int(j+flow[i,j,1]), k] = img[i,j,k]\n",
    "                except: pass\n",
    "                '''\n",
    "                Exception as e:\n",
    "                    print(i,j,k)\n",
    "                    print(img[i,j,k])\n",
    "                    print(flow[i,j,0], flow[i,j,1])\n",
    "                    '''\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# декодер бере 2 збережених кадра та відновлює, той що був між ними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('decoded1.avi',fourcc, 20.0, (360,288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode1(out):\n",
    "    with open('encoded1.npy', 'rb') as f:\n",
    "        encoded = np.load(f)\n",
    "\n",
    "    t1 = time.time()\n",
    "    i = 1\n",
    "    for x in encoded:\n",
    "        img = np.uint8(x[:,:,:3])\n",
    "        #print(img.shape)\n",
    "        flow = x[:,:,3:]\n",
    "        #print(flow.shape)\n",
    "        pred = apply_flow(img, flow)\n",
    "        out.write(img)\n",
    "        out.write(pred)\n",
    "        i += 2\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    out.release()        \n",
    "    return (t2 - t1)/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = decode1(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6995554133022532\n"
     ]
    }
   ],
   "source": [
    "print(time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# обраховуємо візуальну різницю між оригіналом та відновленим кадром"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# другий метод на основі Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_flow2(img, p0, p1):\n",
    "\ttmp = img\n",
    "\tq0 = np.array(p0)\n",
    "\tq1 = np.array(p1)\n",
    "\te = 2*(q1 - q0)\n",
    "\tfor i in range(e.shape[0]):\n",
    "\n",
    "\t\ttry:\n",
    "\n",
    "\t\t\tfor q in range(int(q0[i,0,0]) - 5, int(q0[i,0,0]) +5):\n",
    "\n",
    "\t\t\t\tfor p in range(int(q0[i,0,1]) - 5, int(q0[i,0,1]) +5):\n",
    "\n",
    "\t\t\t\t\tfor k in range(3):\n",
    "\n",
    "\t\t\t\t\t\ttmp[q + int(e[i,0,0]), p + int(e[i,0,1]),k] = img[q, p,k]\n",
    "\t\texcept: pass\n",
    "\t#except: print('##')\n",
    "\treturn tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode2(cap, path):\n",
    "    encoded = []\n",
    "    \n",
    "    feature_params = dict( maxCorners = 500,\n",
    "                                                 qualityLevel = 0.2,\n",
    "                                                 minDistance = 10,\n",
    "                                                 blockSize = 20)\n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                                        maxLevel = 2,\n",
    "                                        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    color = np.random.randint(0,255,(100,3))\n",
    "    \n",
    "    ret, previmg = cap.read()\n",
    "    \n",
    "    i = 1\n",
    "    while (True):\n",
    "        ret, img = cap.read()\n",
    "        if (ret == 0): break\n",
    "        if (i % 2 == 0 ):\n",
    "            previmg = img\n",
    "        else:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            prevgray = cv2.cvtColor(previmg, cv2.COLOR_BGR2GRAY)\n",
    "            p0 = cv2.goodFeaturesToTrack(prevgray, mask = None, **feature_params)\n",
    "            p1, _, _ = cv2.calcOpticalFlowPyrLK(prevgray, gray, p0, None, **lk_params)\n",
    "            encoded.append(previmg)\n",
    "            #print(p0)\n",
    "            with open(path + f'/p{int(i/2)}.npy', 'wb') as f:\n",
    "                np.save(f, np.concatenate((p0, p1), axis = 0))\n",
    "        i += 1\n",
    "        \n",
    "        ch = 0xFF & cv2.waitKey(5)\n",
    "        if ch == 27:\n",
    "            break\n",
    "            \n",
    "    with open(path + '/encoded2.npy', 'wb') as f:\n",
    "        np.save(f, encoded)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode2(cap, \"encoded_video2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('decoded2.avi',fourcc, 20.0, (360,288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode2(out, path):\n",
    "    t1 = time.time()\n",
    "    with open(path+'/encoded2.npy', 'rb') as f:\n",
    "        encoded = np.load(f)\n",
    "    encoded = np.uint8(encoded)\n",
    "        \n",
    "        \n",
    "    i = 0\n",
    "    while(1):\n",
    "        try:\n",
    "            with open(path+f'/p{i}.npy', 'rb') as f:\n",
    "                p = np.load(f)\n",
    "            p0 = p[:int(p.shape[0]/2)]\n",
    "            p1 = p[int(p.shape[0]/2):]\n",
    "            pred = apply_flow2(encoded[i], p0, p1)\n",
    "            #cv2.imwrite(f'img{i}.jpg', pred)\n",
    "            out.write(encoded[i])\n",
    "            #print(encoded[i].shape)\n",
    "            out.write(pred)\n",
    "            #print(pred.shape)\n",
    "\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "            if k == 27:\n",
    "                    break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        except:\n",
    "            out.release()\n",
    "            break\n",
    "        '''\n",
    "        if (i == 8): \n",
    "            out.release() \n",
    "            return \n",
    "        ''' \n",
    "            \n",
    "            \n",
    "    t2 = time.time()\n",
    "\n",
    "    out.release()        \n",
    "    return (t2 - t1)/i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ми бачимо, що farneback працює довше за рахонук зміщення всіх пікселів зображення. але мінусом є те, що не завжди зміщення є правильно нормлваним і пікселі перескакують надто далеко. Lucas-Kanade навпаки не завжди дектектить ключові точки і врезультвті ми бачимо кадр майже ідентичний попередньому. В обох методах є потенціал для покращення, що звичайно ж приведе до більшої складності алгоритму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2 = decode2(out, \"encoded_video2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.026064955963278718\n"
     ]
    }
   ],
   "source": [
    "print(time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('difference.avi',fourcc, 20.0, (360,288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(cap_d, cap_o, out):\n",
    "    ret_d, img_d = cap_d.read()\n",
    "    ret_o, img_o = cap_o.read()\n",
    "    \n",
    "    q = 0\n",
    "    scores = []\n",
    "    while True:\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        ret_d, after = cap_d.read()\n",
    "        ret_o, before = cap_o.read()\n",
    "        \n",
    "        if (q%2 == 0): \n",
    "            out.write(before)\n",
    "            q += 1\n",
    "            continue\n",
    "        \n",
    "        if(ret_d == 0 & ret_o == 0): break\n",
    "        \n",
    "        #before = cv2.imread(path1 + f\"{q}.png\", cv2.IMREAD_COLOR)\n",
    "        #after = cv2.imread(path2 + f\"{q}.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Convert images to grayscale\n",
    "        before_gray = cv2.cvtColor(before, cv2.COLOR_BGR2GRAY)\n",
    "        after_gray = cv2.cvtColor(after, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Compute SSIM between two images\n",
    "        (score, diff) = compare_ssim(before_gray, after_gray, full=True)\n",
    "        #print(\"Image similarity\", score)\n",
    "        scores.append(score)\n",
    "\n",
    "        # The diff image contains the actual image differences between the two images\n",
    "        # and is represented as a floating point data type in the range [0,1] \n",
    "        # so we must convert the array to 8-bit unsigned integers in the range\n",
    "        # [0,255] before we can use it with OpenCV\n",
    "        diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "    # Threshold the difference image, followed by finding contours to\n",
    "    # obtain the regions of the two input images that differ\n",
    "        thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "        filled_after = after.copy()\n",
    "\n",
    "        for c in contours:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area > 40:\n",
    "                x,y,w,h = cv2.boundingRect(c)\n",
    "                cv2.rectangle(after, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "                cv2.drawContours(filled_after, [c], 0, (0,150,0), -1)\n",
    "\n",
    "        for i in range(before.shape[0]):\n",
    "            for j in range(before.shape[1]):\n",
    "                for k in range(before.shape[2]):\n",
    "                    filled_after[i,j,k] = (int(filled_after[i,j,k]) + int(after[i,j,k])) / 2\n",
    "\n",
    "        out.write(filled_after)\n",
    "        #cv2.imshow(\"display\", filled_after);\n",
    "        q += 1\n",
    "    scores = np.array(scores)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_d = cv2.VideoCapture('decoded1.avi')\n",
    "cap_o = cv2.VideoCapture('slow.avi')\n",
    "scores = difference(cap_d, cap_o, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5701563965642287\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38564bitvenvvenvbb0797dc0c4d41bfb6da2398c283d06b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}